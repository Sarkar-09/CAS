{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2740446a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Graph Models are running on cuda\n",
      "v16\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from datasets import  DATASETS, get_dataset\n",
    "from architectures import get_architecture\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "from utils import ModelManager\n",
    "from utils import standard_l2_norm\n",
    "from tqdm import tqdm\n",
    "from certify_utils import *\n",
    "import wandb\n",
    "\n",
    "import cp.transformations as cp_t\n",
    "import cp.graph_transformations as cp_gt\n",
    "from cp.graph_cp import GraphCP\n",
    "import pickle\n",
    "from easydict import EasyDict\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e9f3ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api()\n",
    "runs = api.runs(\"run_name\")\n",
    "all_run = []\n",
    "for run in runs:\n",
    "    if run.state != 'finished':\n",
    "        continue\n",
    "    config = run.config\n",
    "    run.name\n",
    "    row = pd.Series(config)\n",
    "    row.name = run.name\n",
    "    row.acc =  run.history().to_dict()['acc'][0]\n",
    "    row.trained_noirse= float(re.search(r'noise_(\\d+\\.\\d+)', row.checkpoint).group(1))\n",
    "    all_run.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4b5f9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs_df = pd.concat(all_run, axis=1).T.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e8e9c5-3494-4462-be54-4ec371d72184",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0 # 1, 2\n",
    "args = EasyDict(configs_df.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1775681",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pkl(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da776e77-763c-47e0-9422-8b737d20ae3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = \"APS\" # TPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6af879-c4c3-42ac-a514-06d689377cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_logits = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec5b5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, logits, y_true = load_pkl(f'{path_to_logits}/y_pred_logits_y_true.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d79c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = ((y_pred == y_true).sum() / y_true.shape[0]).item()\n",
    "print(f\"acc = {acc}\")\n",
    "y_true_mask = F.one_hot(y_true).bool()\n",
    "\n",
    "#APS\n",
    "if method == \"APS\":\n",
    "    cp = GraphCP(transformation_sequence=[cp_t.APSTransformation(softmax=True)], coverage_guarantee=0.9)\n",
    "    sc_scores = torch.stack([cp.get_scores_from_logits(logits[:, i, :]) for i in range(logits.shape[1])]).permute(1, 2, 0) + 1\n",
    "elif method == \"TPS\":\n",
    "    cp = GraphCP(transformation_sequence=[cp_t.TPSTransformation(softmax=True)], coverage_guarantee=0.9)\n",
    "    sc_scores = torch.stack([cp.get_scores_from_logits(logits[:, i, :]) for i in range(logits.shape[1])]).permute(1, 2, 0) \n",
    "\n",
    "esc_scores = sc_scores.mean(axis=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc261066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "radi_range = [0.    0.125 0.25  0.375 0.5   0.75 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [02:53<00:00, 28.89s/it]\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "coverages = np.array([0.7,0.8, 0.85, 0.9, 0.95]) \n",
    "radi_range = np.array([0, 0.25, 0.5, 0.75, 1, 1.5]) * args.smoothing_sigma\n",
    "print(f\"radi_range = {radi_range}\")\n",
    "\n",
    "for radi in tqdm(radi_range):\n",
    "    np_upper = np_upperbound_tensor(sc_scores, SIGMA=args.smoothing_sigma, radi=radi, n_classes=num_classes, alpha=args.alpha)\n",
    "    dkw_upper = dkw_upperbound_tensor(sc_scores, SIGMA=args.smoothing_sigma, radi=radi, n_classes=num_classes, alpha=args.alpha)\n",
    "\n",
    "    rscp_upper = esc_scores + radi / args.smoothing_sigma\n",
    "\n",
    "    for args.coverage_guarantee in coverages:\n",
    "        cp.coverage_guarantee = args.coverage_guarantee\n",
    "        for iter_i in range(args.n_iters):\n",
    "\n",
    "            cal_mask = get_cal_mask(esc_scores, fraction=args.fraction)\n",
    "            eval_mask = ~cal_mask\n",
    "\n",
    "            cp.calibrate_from_scores(esc_scores[cal_mask], y_true_mask[cal_mask])\n",
    "            np_pred_set = cp.predict_from_scores(np_upper[eval_mask])\n",
    "            dkw_pred_set = cp.predict_from_scores(dkw_upper[eval_mask])\n",
    "\n",
    "            result.append({\n",
    "                \"SIGMA\": args.smoothing_sigma,\n",
    "                \"radi\": radi,\n",
    "                \"iter\": iter_i,\n",
    "                \"method\": \"NP\",\n",
    "                \"$1-\\\\alpha$\": args.coverage_guarantee,\n",
    "                \"coverage\": cp.coverage(np_pred_set, y_true_mask[eval_mask]),\n",
    "                \"set_size\": cp.average_set_size(np_pred_set),\n",
    "                \"singleton_hits\": singleton_hit(np_pred_set, y_true_mask[eval_mask]),\n",
    "            })\n",
    "\n",
    "            result.append({\n",
    "                \"SIGMA\": args.smoothing_sigma,\n",
    "                \"radi\": radi,\n",
    "                \"iter\": iter_i,\n",
    "                \"method\": \"DKW\",\n",
    "                \"$1-\\\\alpha$\": args.coverage_guarantee,\n",
    "                \"coverage\": cp.coverage(dkw_pred_set, y_true_mask[eval_mask]),\n",
    "                \"set_size\": cp.average_set_size(dkw_pred_set),\n",
    "                \"singleton_hits\": singleton_hit(dkw_pred_set, y_true_mask[eval_mask]),\n",
    "            })\n",
    "result = pd.DataFrame(result)\n",
    "result.to_csv(f'/result.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
