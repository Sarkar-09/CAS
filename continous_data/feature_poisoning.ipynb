{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install cvxpy\n",
    "# !pip3 install Mosek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device = cuda\n",
      "Torch Graph Models are running on cuda\n",
      "v16\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"device = {device}\")\n",
    "import cp.transformations as cp_t\n",
    "import cp.graph_transformations as cp_gt\n",
    "from cp.graph_cp import GraphCP\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "from utils import ModelManager\n",
    "from utils import standard_l2_norm\n",
    "\n",
    "# assignments\n",
    "datasets_folder = \"path_to_dataset\"\n",
    "models_direction = \"path_to_models\"\n",
    "\n",
    "\n",
    "import cvxpy as convex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_pkl(obj, path):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "def load_pkl(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cal_mask(vals_tensor, fraction=0.1):\n",
    "    perm = torch.randperm(vals_tensor.shape[0])\n",
    "    mask = torch.zeros((vals_tensor.shape[0]), dtype=bool)\n",
    "    cutoff_index = int(vals_tensor.shape[0] * fraction)\n",
    "    mask[perm[:cutoff_index]] = True\n",
    "    return mask\n",
    "\n",
    "def singleton_hit(pred_set, y_true):\n",
    "    return ((pred_set[y_true])[pred_set.sum(axis=1) == 1].sum() / (pred_set).shape[0]).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "randoms = (torch.rand((1000,)) * (0.73 - 0.72)) + 0.72\n",
    "sigma = 0.01\n",
    "\n",
    "def np_upperbound(randoms, SIGMA, radi, alpha=0.05, n_classes=1):\n",
    "    bon_alpha = alpha / n_classes\n",
    "    error = 0\n",
    "    p_upper = torch.minimum(randoms.mean() + error, torch.tensor(1.0).to(randoms.device))\n",
    "    result = norm.cdf(\n",
    "        norm.ppf(p_upper.cpu(), scale=SIGMA) + radi,\n",
    "        scale=SIGMA)\n",
    "    return torch.tensor(result)\n",
    "print(\"NP bound: \", np_upperbound(randoms, pert_radi, sigma))\n",
    "\n",
    "def dkw_upperbound(randoms, SIGMA, radi, alpha=0.05, num_s=1000, n_classes=1, evasion=True):\n",
    "    bon_alpha = alpha / n_classes\n",
    "    error = 0\n",
    "    s_min = 0\n",
    "    s_max = 1\n",
    "    s_seg = torch.linspace(s_min, s_max, num_s + 1)\n",
    "\n",
    "    empi_cdf = torch.minimum(\n",
    "        ((randoms.view(-1, 1) > s_seg.to(randoms.device)).sum(dim=0) / randoms.shape[0]) + error,\n",
    "        torch.tensor([1.0]).to(randoms.device))\n",
    "\n",
    "    result = (norm.cdf(norm.ppf(empi_cdf.cpu(), scale=SIGMA) + radi, scale=SIGMA) * (1 / (num_s))).sum() + (1/num_s)\n",
    "    return torch.tensor(result)\n",
    "print(\"DKW bound: \", dkw_upperbound(randoms, pert_radi, sigma))\n",
    "\n",
    "\n",
    "def dkw_lowerbound(randoms, SIGMA, radi, alpha=0.05, num_s=1000, n_classes=1, evasion=True):\n",
    "    bon_alpha = alpha / n_classes\n",
    "    error = 0\n",
    "    s_min = 0\n",
    "    s_max = 1\n",
    "    s_seg = torch.linspace(s_min, s_max, num_s + 1)\n",
    "\n",
    "    empi_cdf = torch.maximum(\n",
    "        ((randoms.view(-1, 1) > s_seg.to(randoms.device)).sum(dim=0) / randoms.shape[0]) - error,\n",
    "        torch.tensor([0.0]).to(randoms.device))\n",
    "\n",
    "    result = (norm.cdf(norm.ppf(empi_cdf.cpu(), scale=SIGMA) - radi, scale=SIGMA) * (1 / (num_s))).sum()\n",
    "    return torch.tensor(result)\n",
    "\n",
    "\n",
    "def np_upperbound_tensor(scores_samplings, SIGMA, radi, alpha=0.05, n_classes=1):\n",
    "    bon_alpha = alpha / n_classes\n",
    "    # error = np.sqrt(np.log(1 / bon_alpha) / (2 * scores_samplings.shape[-1]))\n",
    "    error = 0\n",
    "    p_uppers = torch.minimum(scores_samplings.mean(dim=-1) + error, torch.tensor(1.0).to(scores_samplings.device))\n",
    "    result = norm.cdf(\n",
    "        norm.ppf(p_uppers.cpu(), scale=SIGMA) + radi,\n",
    "        scale=SIGMA)\n",
    "    return torch.tensor(result).to(scores_samplings.device)\n",
    "\n",
    "def dkw_upperbound_tensor(scores_sampling, SIGMA, radi, alpha=0.05, num_s=10000, n_classes=1):\n",
    "    return torch.stack([\n",
    "        torch.stack([\n",
    "            dkw_upperbound(scores_sampling[d, c, :], SIGMA=SIGMA, radi=radi, alpha=alpha, num_s=num_s, n_classes=n_classes)\n",
    "            for c in range(scores_sampling.shape[1])\n",
    "        ])\n",
    "        for d in range(scores_sampling.shape[0])\n",
    "    ]).to(scores_sampling.device)\n",
    "\n",
    "def dkw_lowerbound_tensor(scores_sampling, SIGMA, radi, alpha=0.05, num_s=10000, n_classes=1):\n",
    "    return torch.stack([\n",
    "        torch.stack([\n",
    "            dkw_lowerbound(scores_sampling[d, c, :], SIGMA=SIGMA, radi=radi, alpha=alpha, num_s=num_s, n_classes=n_classes)\n",
    "            for c in range(scores_sampling.shape[1])\n",
    "        ])\n",
    "        for d in range(scores_sampling.shape[0])\n",
    "    ]).to(scores_sampling.device)\n",
    "\n",
    "\n",
    "def np_bounds_tensor(scores_samplings, SIGMA, radi, alpha=0.05, n_classes=1):\n",
    "    bon_alpha = alpha / n_classes\n",
    "    error = 0\n",
    "    p_uppers = torch.minimum(scores_samplings.mean(dim=-1) + error, torch.tensor(1.0).to(scores_samplings.device))\n",
    "    p_lowers = torch.maximum(scores_samplings.mean(dim=-1) - error, torch.tensor(0.0).to(scores_samplings.device))\n",
    "\n",
    "    upper_result = norm.cdf(\n",
    "        norm.ppf(p_uppers.cpu(), scale=SIGMA) + radi,\n",
    "        scale=SIGMA)\n",
    "    lower_result = norm.cdf(\n",
    "        norm.ppf(p_lowers.cpu(), scale=SIGMA) - radi,\n",
    "        scale=SIGMA)\n",
    "\n",
    "    return torch.tensor(lower_result).to(scores_samplings.device), torch.tensor(upper_result).to(scores_samplings.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_worst_quantile_budget(clean_scores, cal_lower, cal_upper, coverage, no_pert=10):\n",
    "    if isinstance(cal_lower, torch.Tensor):\n",
    "        cal_lower = cal_lower.cpu().numpy()\n",
    "    if isinstance(cal_upper, torch.Tensor):\n",
    "        cal_upper = cal_upper.cpu().numpy()\n",
    "    if isinstance(clean_scores, torch.Tensor):\n",
    "        clean_scores = clean_scores.cpu().numpy()\n",
    "    \n",
    "    alpha = 1 - coverage  # quantile level\n",
    "    M = 10  # large positive number (should be as small as possible)\n",
    "\n",
    "    n = cal_lower.shape[0]\n",
    "\n",
    "    # Variables\n",
    "    y = convex.Variable(n)\n",
    "    q = convex.Variable()\n",
    "    z = convex.Variable(n, boolean=True)\n",
    "    w = convex.Variable(n, boolean=True)\n",
    "\n",
    "\n",
    "\n",
    "    # Constraints\n",
    "    constraints = [\n",
    "        cal_lower <= y,\n",
    "        y <= cal_upper,\n",
    "        convex.sum(z) >= convex.floor(alpha * n),\n",
    "        convex.sum(1 - z) >= (1 - alpha) * n,\n",
    "        y <= q + M * (1 - z),\n",
    "        y >= q - M * z,\n",
    "\n",
    "        convex.sum(w) <= no_pert, #number of perturbed points,\n",
    "        y <= clean_scores + M * w,\n",
    "        y >= clean_scores - M * w\n",
    "    ]\n",
    "\n",
    "    prob = convex.Problem(convex.Maximize(q), constraints).solve(verbose=False, solver='MOSEK')\n",
    "    quantile = torch.tensor(q.value)\n",
    "    return quantile\n",
    "\n",
    "def find_best_quantile_budget(clean_scores, cal_lower, cal_upper, coverage, no_pert=10):\n",
    "    if isinstance(cal_lower, torch.Tensor):\n",
    "        cal_lower = cal_lower.cpu().numpy()\n",
    "    if isinstance(cal_upper, torch.Tensor):\n",
    "        cal_upper = cal_upper.cpu().numpy()\n",
    "    if isinstance(clean_scores, torch.Tensor):\n",
    "        clean_scores = clean_scores.cpu().numpy()\n",
    "    \n",
    "    alpha = 1 - coverage  # quantile level\n",
    "    M = 10  # large positive number (should be as small as possible)\n",
    "\n",
    "    n = cal_lower.shape[0]\n",
    "\n",
    "    # Variables\n",
    "    y = convex.Variable(n)\n",
    "    q = convex.Variable()\n",
    "    z = convex.Variable(n, boolean=True)\n",
    "    w = convex.Variable(n, boolean=True)\n",
    "\n",
    "\n",
    "\n",
    "    # Constraints\n",
    "    constraints = [\n",
    "        cal_lower <= y,\n",
    "        y <= cal_upper,\n",
    "        convex.sum(z) >= convex.floor(alpha * n),\n",
    "        convex.sum(1 - z) >= (1 - alpha) * n,\n",
    "        y <= q + M * (1 - z),\n",
    "        y >= q - M * z,\n",
    "\n",
    "        convex.sum(w) <= no_pert, #number of perturbed points,\n",
    "        y <= clean_scores + M * w,\n",
    "        y >= clean_scores - M * w\n",
    "    ]\n",
    "\n",
    "    prob = convex.Problem(convex.Minimize(q), constraints).solve(verbose=False, solver='MOSEK')\n",
    "    quantile = torch.tensor(q.value)\n",
    "    return quantile\n",
    "\n",
    "\n",
    "def find_worst_quantile(clean_scores, cal_lower, cal_upper, coverage):\n",
    "    if isinstance(cal_lower, torch.Tensor):\n",
    "        cal_lower = cal_lower.cpu().numpy()\n",
    "    if isinstance(cal_upper, torch.Tensor):\n",
    "        cal_upper = cal_upper.cpu().numpy()\n",
    "    if isinstance(clean_scores, torch.Tensor):\n",
    "        clean_scores = clean_scores.cpu().numpy()\n",
    "    \n",
    "    alpha = 1 - coverage  # quantile level\n",
    "    M = 10  # large positive number (should be as small as possible)\n",
    "\n",
    "    n = cal_lower.shape[0]\n",
    "\n",
    "    # Variables\n",
    "    y = convex.Variable(n)\n",
    "    q = convex.Variable()\n",
    "    z = convex.Variable(n, boolean=True)\n",
    "    w = convex.Variable(n, boolean=True)\n",
    "\n",
    "\n",
    "\n",
    "    # Constraints\n",
    "    constraints = [\n",
    "        cal_lower <= y,\n",
    "        y <= cal_upper,\n",
    "        convex.sum(z) >= convex.floor(alpha * n),\n",
    "        convex.sum(1 - z) >= (1 - alpha) * n,\n",
    "        y <= q + M * (1 - z),\n",
    "        y >= q - M * z,\n",
    "    ]\n",
    "\n",
    "    prob = convex.Problem(convex.Maximize(q), constraints).solve(verbose=False, solver='MOSEK')\n",
    "    quantile = torch.tensor(q.value)\n",
    "    return quantile\n",
    "\n",
    "def find_best_quantile(clean_scores, cal_lower, cal_upper, coverage):\n",
    "    if isinstance(cal_lower, torch.Tensor):\n",
    "        cal_lower = cal_lower.cpu().numpy()\n",
    "    if isinstance(cal_upper, torch.Tensor):\n",
    "        cal_upper = cal_upper.cpu().numpy()\n",
    "    if isinstance(clean_scores, torch.Tensor):\n",
    "        clean_scores = clean_scores.cpu().numpy()\n",
    "    \n",
    "    alpha = 1 - coverage  # quantile level\n",
    "    M = 10  # large positive number (should be as small as possible)\n",
    "\n",
    "    n = cal_lower.shape[0]\n",
    "\n",
    "    # Variables\n",
    "    y = convex.Variable(n)\n",
    "    q = convex.Variable()\n",
    "    z = convex.Variable(n, boolean=True)\n",
    "    w = convex.Variable(n, boolean=True)\n",
    "\n",
    "\n",
    "\n",
    "    # Constraints\n",
    "    constraints = [\n",
    "        cal_lower <= y,\n",
    "        y <= cal_upper,\n",
    "        convex.sum(z) >= convex.floor(alpha * n),\n",
    "        convex.sum(1 - z) >= (1 - alpha) * n,\n",
    "        y <= q + M * (1 - z),\n",
    "        y >= q - M * z,\n",
    "    ]\n",
    "\n",
    "    prob = convex.Problem(convex.Minimize(q), constraints).solve(verbose=False, solver='MOSEK')\n",
    "    quantile = torch.tensor(q.value)\n",
    "    return quantile\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, logits, y_true = load_pkl(f'path_to_logits')\n",
    "y_pred = y_pred.to(device)\n",
    "logits = logits.to(device)\n",
    "y_true = y_true.to(device)\n",
    "smoothing_sigma = 0.25\n",
    "pert_radi = 0.12\n",
    "\n",
    "y_true_mask = F.one_hot(y_true).bool()\n",
    "\n",
    "#APS\n",
    "cp = GraphCP(transformation_sequence=[cp_t.APSTransformation(softmax=True)], coverage_guarantee=0.9)\n",
    "sc_scores = torch.stack([cp.get_scores_from_logits(logits[:, i, :]) for i in range(logits.shape[1])]).permute(1, 2, 0) + 1\n",
    "esc_scores = sc_scores.mean(axis=2)\n",
    "esc_scores.shape\n",
    "\n",
    "n_classes = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.    , 0.0625, 0.125 , 0.1875, 0.25  , 0.375 ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([0, 0.25, 0.5, 0.75, 1, 1.5]) * smoothing_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:08<00:00, 11.77it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:06<00:00, 15.11it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:03<00:00, 26.65it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:02<00:00, 33.63it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:08<00:00, 11.41it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:12<00:00,  8.31it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:23<00:00,  4.18it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:36<00:00,  2.77it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:32<00:00,  3.07it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [01:12<00:00,  1.37it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [03:10<00:00,  1.91s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [05:19<00:00,  3.19s/it]\n"
     ]
    }
   ],
   "source": [
    "coverage = 0.9\n",
    "coverages = np.array([0.8, 0.85, 0.9, 0.95]) \n",
    "pert_radis =  np.array([ 0.25, 0.5, 0.75]) * smoothing_sigma\n",
    "nb_results = []\n",
    "\n",
    "for pert_radi in pert_radis:\n",
    "    np_lower, np_upper = np_bounds_tensor(sc_scores, SIGMA=smoothing_sigma, radi=pert_radi, alpha=0.05, n_classes=n_classes)\n",
    "    for coverage in coverages:\n",
    "        for iter_i in tqdm(range(100)):\n",
    "            cal_mask = get_cal_mask(sc_scores, fraction=0.1)\n",
    "            cal_lower = np_lower[cal_mask][y_true_mask[cal_mask]]\n",
    "            cal_upper = np_upper[cal_mask][y_true_mask[cal_mask]]\n",
    "            cal_scores = esc_scores[cal_mask][y_true_mask[cal_mask]]\n",
    "            eval_mask = ~cal_mask\n",
    "\n",
    "\n",
    "            best_q = find_best_quantile(cal_scores, cal_lower, cal_upper, coverage=coverage)\n",
    "\n",
    "            best_pred_sets = (esc_scores >= best_q)\n",
    "\n",
    "            nb_results.append({\n",
    "                \"iter_i\": iter_i,\n",
    "                'best_q': best_q.item(),\n",
    "                'actual_q': cp.calibrate_from_scores(esc_scores[cal_mask], y_true_mask[cal_mask]),\n",
    "                'best_coverage': cp.coverage(best_pred_sets[eval_mask], y_true_mask[eval_mask]),\n",
    "                'best_ave_set_size': cp.average_set_size(best_pred_sets[eval_mask]),\n",
    "                'best_singleton_hits': singleton_hit(best_pred_sets, y_true_mask),\n",
    "                '$1-\\alpha$': coverage,\n",
    "                'radi': pert_radi\n",
    "\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(nb_results).to_csv('./poisoning_np_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:07<00:00, 13.05it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:04<00:00, 23.96it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:02<00:00, 35.12it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:02<00:00, 42.00it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:07<00:00, 13.15it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:06<00:00, 14.34it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:04<00:00, 22.16it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:03<00:00, 28.04it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:09<00:00, 10.94it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:10<00:00,  9.54it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:19<00:00,  5.09it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:48<00:00,  2.07it/s]\n"
     ]
    }
   ],
   "source": [
    "coverages = np.array([0.8, 0.85, 0.9, 0.95]) \n",
    "pert_radis =  np.array([0.25, 0.5, 0.75]) * smoothing_sigma\n",
    "dnp_results = []\n",
    "for pert_radi in pert_radis:\n",
    "    for coverage in coverages:\n",
    "        dkw_lower = dkw_lowerbound_tensor(sc_scores, SIGMA=smoothing_sigma, radi=pert_radi, alpha=0.05, num_s=10000, n_classes=n_classes)\n",
    "        dkw_upper = dkw_upperbound_tensor(sc_scores, SIGMA=smoothing_sigma, radi=pert_radi, alpha=0.05, num_s=10000, n_classes=n_classes)\n",
    "        for iter_i in tqdm(range(100)):\n",
    "            cal_mask = get_cal_mask(sc_scores, fraction=0.1)\n",
    "            cal_lower = dkw_lower[cal_mask][y_true_mask[cal_mask]]\n",
    "            cal_upper = dkw_upper[cal_mask][y_true_mask[cal_mask]]\n",
    "            cal_scores = esc_scores[cal_mask][y_true_mask[cal_mask]]\n",
    "            eval_mask = ~cal_mask\n",
    "\n",
    "\n",
    "            best_q = find_best_quantile(cal_scores, cal_lower, cal_upper, coverage=coverage)\n",
    "\n",
    "            best_pred_sets = (esc_scores >= best_q)\n",
    "\n",
    "            dnp_results.append({\n",
    "                \"iter_i\": iter_i,\n",
    "                'best_q': best_q.item(),\n",
    "                'actual_q': cp.calibrate_from_scores(esc_scores[cal_mask], y_true_mask[cal_mask]),\n",
    "                'best_coverage': cp.coverage(best_pred_sets[eval_mask], y_true_mask[eval_mask]),\n",
    "                'best_ave_set_size': cp.average_set_size(best_pred_sets[eval_mask]),\n",
    "                'best_singleton_hits': singleton_hit(best_pred_sets, y_true_mask),\n",
    "                '$1-\\alpha$': coverage,\n",
    "                'radi': pert_radi\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(dnp_results).to_csv('./poisoning_dkw_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# constraint optimization (with budget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pert_budget_range = [1,2,3]\n",
    "coverage = 0.85\n",
    "\n",
    "for iter_i in tqdm(range(100)):\n",
    "    cal_mask = get_cal_mask(sc_scores, fraction=0.1)\n",
    "    cal_lower = np_lower[cal_mask][y_true_mask[cal_mask]]\n",
    "    cal_upper = np_upper[cal_mask][y_true_mask[cal_mask]]\n",
    "    cal_scores = esc_scores[cal_mask][y_true_mask[cal_mask]]\n",
    "    eval_mask = ~cal_mask\n",
    "    \n",
    "    for pert_budget in pert_budget_range:\n",
    "\n",
    "        best_q = find_best_quantile_budget(cal_scores, cal_lower, cal_upper, coverage=coverage, no_pert=pert_budget)\n",
    "\n",
    "        best_pred_sets = (esc_scores >= best_q)\n",
    "    \n",
    "\n",
    "        results.append({\n",
    "            \"iter_i\": iter_i,\n",
    "            'pert_budget': pert_budget,\n",
    "            'best_q': best_q.item(),\n",
    "            'actual_q': cp.calibrate_from_scores(esc_scores[cal_mask], y_true_mask[cal_mask]),\n",
    "            'best_coverage': cp.coverage(best_pred_sets[eval_mask], y_true_mask[eval_mask]),\n",
    "            'best_ave_set_size': cp.average_set_size(best_pred_sets[eval_mask]),\n",
    "            'best_singleton_hits': singleton_hit(best_pred_sets, y_true_mask),\n",
    "            'coverage': coverage\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv('./poisoning_wbudget.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
