{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install statsmodels\n",
    "# !pip3 install gmpy2\n",
    "# !pip3 install cvxpy\n",
    "# !pip install Mosek\n",
    "# !pip install ipywidgets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device = cpu\n",
      "Torch Graph Models are running on cpu\n",
      "v16\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"device = {device}\")\n",
    "\n",
    "import cp.transformations as cp_t\n",
    "import cp.graph_transformations as cp_gt\n",
    "from cp.graph_cp import GraphCP\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "from utils import ModelManager\n",
    "from utils import standard_l2_norm\n",
    "\n",
    "# assignments\n",
    "datasets_folder = \"path_datasets\"\n",
    "models_direction = \"path_to_model\"\n",
    "\n",
    "\n",
    "import cvxpy as convex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pert_radi=0.12\n",
    "smoothing_sigma = 0.25\n",
    "\n",
    "def save_pkl(obj, path):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "def load_pkl(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "y_pred, logits, y_true = load_pkl(f'path_to_logits')\n",
    "y_pred = y_pred.to(device)\n",
    "logits = logits.to(device)\n",
    "y_true = y_true.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NP bound:  tensor(0.7885, dtype=torch.float64)\n",
      "DKW bound:  tensor(0.7378, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "randoms = (torch.rand((1000,)) * (0.73 - 0.72)) + 0.72\n",
    "sigma = 0.01\n",
    "\n",
    "def np_upperbound(randoms, SIGMA, radi, alpha=0.05, n_classes=1):\n",
    "    bon_alpha = alpha / n_classes\n",
    "    error = 0\n",
    "    p_upper = torch.minimum(randoms.mean() + error, torch.tensor(1.0).to(randoms.device))\n",
    "    result = norm.cdf(\n",
    "        norm.ppf(p_upper.cpu(), scale=SIGMA) + radi,\n",
    "        scale=SIGMA)\n",
    "    return torch.tensor(result)\n",
    "print(\"NP bound: \", np_upperbound(randoms, pert_radi, sigma))\n",
    "\n",
    "def dkw_upperbound(randoms, SIGMA, radi, alpha=0.05, num_s=1000, n_classes=1, evasion=True):\n",
    "    bon_alpha = alpha / n_classes\n",
    "    error = 0\n",
    "    s_min = 0\n",
    "    s_max = 1\n",
    "    s_seg = torch.linspace(s_min, s_max, num_s)\n",
    "\n",
    "    empi_cdf = torch.minimum(\n",
    "        ((randoms.view(-1, 1) > s_seg.to(randoms.device)).sum(dim=0) / randoms.shape[0]) + error,\n",
    "        torch.tensor([1.0]).to(randoms.device))\n",
    "\n",
    "    result = (norm.cdf(norm.ppf(empi_cdf.cpu(), scale=SIGMA) + radi, scale=SIGMA) * (1 / (num_s))).sum()\n",
    "    return torch.tensor(result)\n",
    "print(\"DKW bound: \", dkw_upperbound(randoms, pert_radi, sigma))\n",
    "\n",
    "\n",
    "def dkw_lowerbound(randoms, SIGMA, radi, alpha=0.05, num_s=1000, n_classes=1, evasion=True):\n",
    "    bon_alpha = alpha / n_classes\n",
    "    error = 0\n",
    "    s_min = 0\n",
    "    s_max = 1\n",
    "    s_seg = torch.linspace(s_min, s_max, num_s)\n",
    "\n",
    "    empi_cdf = torch.maximum(\n",
    "        ((randoms.view(-1, 1) > s_seg.to(randoms.device)).sum(dim=0) / randoms.shape[0]) - error,\n",
    "        torch.tensor([0.0]).to(randoms.device))\n",
    "\n",
    "    result = (norm.cdf(norm.ppf(empi_cdf.cpu(), scale=SIGMA) - radi, scale=SIGMA) * (1 / (num_s))).sum()\n",
    "    return torch.tensor(result)\n",
    "\n",
    "\n",
    "def np_upperbound_tensor(scores_samplings, SIGMA, radi, alpha=0.05, n_classes=1):\n",
    "    bon_alpha = alpha / n_classes\n",
    "    error = 0\n",
    "    p_uppers = torch.minimum(scores_samplings.mean(dim=-1) + error, torch.tensor(1.0).to(scores_samplings.device))\n",
    "    result = norm.cdf(\n",
    "        norm.ppf(p_uppers.cpu(), scale=SIGMA) + radi,\n",
    "        scale=SIGMA)\n",
    "    return torch.tensor(result).to(scores_samplings.device)\n",
    "\n",
    "def dkw_upperbound_tensor(scores_sampling, SIGMA, radi, alpha=0.05, num_s=10000, n_classes=1):\n",
    "    return torch.stack([\n",
    "        torch.stack([\n",
    "            dkw_upperbound(scores_sampling[d, c, :], SIGMA=SIGMA, radi=radi, alpha=alpha, num_s=num_s, n_classes=n_classes)\n",
    "            for c in range(scores_sampling.shape[1])\n",
    "        ]) \n",
    "        for d in range(scores_sampling.shape[0])\n",
    "    ]).to(scores_sampling.device)\n",
    "\n",
    "def dkw_lowerbound_tensor(scores_sampling, SIGMA, radi, alpha=0.05, num_s=10000, n_classes=1):\n",
    "    return torch.stack([\n",
    "        torch.stack([\n",
    "            dkw_lowerbound(scores_sampling[d, c, :], SIGMA=SIGMA, radi=radi, alpha=alpha, num_s=num_s, n_classes=n_classes)\n",
    "            for c in range(scores_sampling.shape[1])\n",
    "        ]) \n",
    "        for d in range(scores_sampling.shape[0])\n",
    "    ]).to(scores_sampling.device)\n",
    "\n",
    "\n",
    "def np_bounds_tensor(scores_samplings, SIGMA, radi, alpha=0.05, n_classes=1):\n",
    "    bon_alpha = alpha / n_classes\n",
    "    error = np.sqrt(np.log(1 / bon_alpha) / (2 * scores_samplings.shape[-1]))\n",
    "    p_uppers = torch.minimum(scores_samplings.mean(dim=-1) + error, torch.tensor(1.0).to(scores_samplings.device))\n",
    "    p_lowers = torch.maximum(scores_samplings.mean(dim=-1) - error, torch.tensor(0.0).to(scores_samplings.device))\n",
    "\n",
    "    upper_result = norm.cdf(\n",
    "        norm.ppf(p_uppers.cpu(), scale=SIGMA) + radi,\n",
    "        scale=SIGMA)\n",
    "    lower_result = norm.cdf(\n",
    "        norm.ppf(p_lowers.cpu(), scale=SIGMA) - radi,\n",
    "        scale=SIGMA)\n",
    "    \n",
    "    return torch.tensor(lower_result).to(scores_samplings.device), torch.tensor(upper_result).to(scores_samplings.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cal_mask(vals_tensor, fraction=0.1):\n",
    "    perm = torch.randperm(vals_tensor.shape[0])\n",
    "    mask = torch.zeros((vals_tensor.shape[0]), dtype=bool)\n",
    "    cutoff_index = int(vals_tensor.shape[0] * fraction)\n",
    "    mask[perm[:cutoff_index]] = True\n",
    "    return mask\n",
    "\n",
    "def singleton_hit(pred_set, y_true):\n",
    "    return ((pred_set[y_true])[pred_set.sum(axis=1) == 1].sum() / (pred_set).shape[0]).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lpoisoning_quantile(scores, true_cal_mask, coverage=0.9, k=2):\n",
    "\n",
    "    calibration_labels = true_cal_mask.nonzero(as_tuple=True)[1].cpu().numpy()\n",
    "\n",
    "    n = scores.shape[0]\n",
    "    alpha = 1 - coverage\n",
    "    M = 10  # large positive number (should be as small as possible)\n",
    "    q = convex.Variable()\n",
    "    z = convex.Variable(n, boolean=True)\n",
    "    b = convex.Variable(scores.shape, boolean=True)\n",
    "\n",
    "    y = convex.sum(convex.multiply(scores, b), 1)\n",
    "\n",
    "    constraints = [\n",
    "        convex.sum(z) >= convex.floor(alpha * n),\n",
    "        convex.sum(1 - z) >= (1 - alpha) * n,\n",
    "        y <= q + M * (1 - z),\n",
    "        y >= q - M * z,\n",
    "        convex.sum(b, 1) == 1, # at most one label per node\n",
    "        convex.sum(1-b[np.arange(n), calibration_labels]) <= k # at most k changed\n",
    "    ]\n",
    "\n",
    "    prob = convex.Problem(convex.Minimize(q), constraints).solve()\n",
    "    return prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothing_sigma = 0.25\n",
    "\n",
    "y_true_mask = F.one_hot(y_true).bool()\n",
    "cp = GraphCP(transformation_sequence=[cp_t.APSTransformation(softmax=True)], coverage_guarantee=0.9)\n",
    "sc_scores = torch.stack([cp.get_scores_from_logits(logits[:, i, :]) for i in range(logits.shape[1])]).permute(1, 2, 0) + 1\n",
    "esc_scores = sc_scores.mean(axis=2)\n",
    "esc_scores.shape\n",
    "esc_scores = esc_scores.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [08:01<00:00, 48.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████████████▌                                              | 5/10 [29:16<30:50, 370.02s/it]"
     ]
    }
   ],
   "source": [
    "coverages = np.array([0.9])\n",
    "result = []\n",
    "for budget in [1,2,3]:\n",
    "    for coverage in coverages:\n",
    "        print(coverage, budget)\n",
    "        for iter_i in tqdm(range(10)):\n",
    "            cal_mask = get_cal_mask(esc_scores, 0.1)\n",
    "            true_cal_mask = y_true_mask[cal_mask]\n",
    "            eval_mask = ~cal_mask\n",
    "\n",
    "            cons_q = find_lpoisoning_quantile(esc_scores[cal_mask], true_cal_mask, coverage=coverage, k=budget)\n",
    "            pred_set = (esc_scores >= cons_q)\n",
    "\n",
    "            result.append({\n",
    "            \"iter_i\": iter_i,\n",
    "            \"cons_q\": cons_q,\n",
    "            \"empi_coverage\": cp.coverage(pred_set[eval_mask], y_true[eval_mask]),\n",
    "            \"set_size\": cp.average_set_size(pred_set[eval_mask]),\n",
    "            \"singleton_hit\": singleton_hit(pred_set[eval_mask], y_true[eval_mask]),\n",
    "            \"1-\\\\alpha\": coverage,\n",
    "            \"k\": budget\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
